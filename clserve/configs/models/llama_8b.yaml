model_path: meta-llama/Llama-3.1-8B-Instruct
dp_size: 4
num_gpus_per_worker: 1
use_router: true
router_policy: cache_aware
